{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb65131-d123-492d-b6ef-85eeb9ed1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/newpy37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaConfig, RobertaTokenizer, RobertaModel\n",
    "from model_CodeBERT import Seq2Seq\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy as cp\n",
    "import renew_bleu\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "592174b3-10ac-4da2-b04d-abf62cbec79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4990167-62a4-48ff-ae5a-4ea4aa2749a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of C++ code files is: 9289\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "with open(\"selected_files.txt\", \"r\") as f: # selected_files\n",
    "    for l in f.readlines():\n",
    "        filenames.append(l.strip())\n",
    "num_of_files = len(filenames)\n",
    "print(\"Number of C++ code files is: {}\".format(num_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a75237-74bd-4b03-939e-d0487c632781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeDataset (Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        func = \"\"\n",
    "        func_file = \"func/{}.cpp\".format(self.filenames[index])\n",
    "        with open(func_file, \"r\") as f:\n",
    "            for l in f.readlines():\n",
    "                func += l\n",
    "        func = \" \".join(func.replace('\\n', \" \").split())\n",
    "\n",
    "        label = \"\"\n",
    "        label_file = \"label/{}.text\".format(self.filenames[index])\n",
    "        with open(label_file, \"r\") as f:\n",
    "            for l in f.readlines():\n",
    "                label += l\n",
    "        label = label.replace('//', \" \").replace('/*', \" \").replace('*/', \" \").replace('\\n', \" \")\n",
    "        label = \" \".join(label.split())\n",
    "        \n",
    "        return func, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3c448d-6bb5-4d5b-b182-7a1eb0e7bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 7431\n",
      "('void print(int mat[][MAX], int n, int m) { for (int i = 0; i < n; i++) { for (int j = 0; j < m; j++) { cout << mat[i][j] << \" \"; } cout << endl; } }', 'Function to print the resultant matrix')\n",
      "\n",
      "validation sample size: 928\n",
      "('unsigned int doublefactorial(unsigned int n) { if (n == 0 || n==1) return 1; return n*doublefactorial(n-2); }', 'function to find double factorial of given number')\n",
      "\n",
      "Test sample size: 930\n",
      "('void push(Node** head_ref, int new_data) { Node* new_node = new Node(); new_node->data = new_data; new_node->next = (*head_ref); (*head_ref) = new_node; }', 'function to add a new node at the beginning of the list')\n"
     ]
    }
   ],
   "source": [
    "size_t = int(num_of_files * 0.8)\n",
    "size_val = int(num_of_files * 0.1)\n",
    "train_data = CodeDataset(filenames[:5])\n",
    "train_data = CodeDataset(filenames[:size_t])\n",
    "val_data = CodeDataset(filenames[size_t:size_t+size_val])\n",
    "test_data = CodeDataset(filenames[size_t+size_val:])\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "print(\"Training sample size: {}\".format(size_t))\n",
    "print(train_data[1])\n",
    "print(\"\")\n",
    "print(\"validation sample size: {}\".format(size_val))\n",
    "print(val_data[1])\n",
    "print(\"\")\n",
    "print(\"Test sample size: {}\".format(num_of_files-size_t-size_val))\n",
    "print(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60b8787-0002-472b-9f56-8ac38fe4ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model (use defaul parameters)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "config  = RobertaConfig.from_pretrained(\"microsoft/codebert-base\")\n",
    "encoder = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "decoder_layer = torch.nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "627dc953-27e6-46f0-97c0-35dd44f64b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = []\n",
    "for func, label in train_loader:\n",
    "    for codes in func:\n",
    "        token_length.append(len(tokenizer(codes)[\"input_ids\"]))\n",
    "\n",
    "mean_length = np.mean(token_length)\n",
    "min_length = min(token_length)\n",
    "max_length = max(token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e746182-0a3d-4eda-9043-d9aacfe97c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of token length: 60.97160543668416\n",
      "Min of token length: 7\n",
      "Max of token length: 149\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Mean of token length: {}\".format(mean_length))\n",
    "print(\"Min of token length: {}\".format(min_length))\n",
    "print(\"Max of token length: {}\".format(max_length))\n",
    "bins = np.arange(min_length, max_length, 50) \n",
    "plt.xlim([min_length-5, max_length+5])\n",
    "plt.hist(token_length, bins=bins, alpha=0.8)\n",
    "plt.title('Histogram of token length')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf23f09-1afc-4620-8e71-47385da8dd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a seq2seq model\n",
    "model = Seq2Seq(\n",
    "    encoder=encoder, \n",
    "    decoder=decoder, \n",
    "    config=config,\n",
    "    beam_size=10, # beam size for beam search, default = 10\n",
    "    max_length=128, # output tokens length\n",
    "    sos_id=tokenizer.cls_token_id, # start of symbol ids in target for beam search\n",
    "    eos_id=tokenizer.sep_token_id  # end of symbol ids in target for beam search. \n",
    ")\n",
    "\n",
    "# load pretrained model\n",
    "pytorch_model = \"./PretrainedModel/java/pytorch_model.bin\"\n",
    "checkpoint = torch.load(pytorch_model, map_location='cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379f7e2a-2981-4ae6-8a25-b061c76a8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tokens(codes, tokenizer, truncation, max_length):\n",
    "    tokens = tokenizer(codes, truncation=truncation, padding=\"max_length\", max_length=max_length)\n",
    "    codes_ids = torch.tensor(tokens[\"input_ids\"])\n",
    "    codes_mask = torch.tensor(tokens[\"attention_mask\"])\n",
    "    return codes_ids.to(device), codes_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d170e57-061a-48b2-a9e4-231c89cc04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_labels(tokens, tokenizer):\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        t_seq = list(token[0].cpu().numpy())\n",
    "        if 0 in t_seq: \n",
    "            t_seq = t_seq[:t_seq.index(0)]\n",
    "        label = tokenizer.decode(t_seq, clean_up_tokenization_spaces=False)\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c46c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cb2aba-0362-4673-b651-634d8549d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# using pre-trained model to make a test\n",
    "model.eval()\n",
    "codes_act = []\n",
    "labels_act = []\n",
    "labels_pred = []\n",
    "for i, (codes, labels) in enumerate(test_loader):\n",
    "    codes_act.extend(codes)\n",
    "    labels_act.extend(labels)\n",
    "    codes_ids, codes_mask = convert_to_tokens(codes, tokenizer, True, MAX_LENGTH)\n",
    "    tokens = model(source_ids=codes_ids, source_mask=codes_mask)\n",
    "    labels_output = tokens_to_labels(tokens, tokenizer)\n",
    "    labels_pred.extend(labels_output)\n",
    "    if i%10==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2956e5-751d-4c2c-a881-c1eff6ce6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu4_score(labels_pred, labels_act):\n",
    "    (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "    bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "    return round(bleu4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b190325-9b4a-4c93-97bc-707ffef8699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU-4 score using the pre-trained model: 0.1421.\n",
      "\n",
      "Examples using pre-trained model\n",
      "1\n",
      "unsigned int aModM(string s, unsigned int mod) { unsigned int number = 0; for (unsigned int i = 0; i < s.length(); i++) { number = (number*10 + (s[i] - '0')); number %= mod; } return number; }\n",
      "\n",
      "utility function to calculate a%m\n",
      "\n",
      "Calculate the number of digits .\n",
      "\n",
      "2\n",
      "int nextChar(int freq[], int dist[]) { int max = INT_MIN; for (int i = 0; i < MAX_CHAR; i++) if (dist[i] <= 0 && freq[i] > 0 && (max == INT_MIN || freq[i] > freq[max])) max = i; return max; }\n",
      "\n",
      "The function returns next eligible character with maximum frequency (Greedy!!) and zero or negative distance\n",
      "\n",
      "Returns the next character .\n",
      "\n",
      "3\n",
      "void find_min(struct node* mini) { cout << \"min of heap is: \" << mini->key << endl; }\n",
      "\n",
      "Function to find min node in the heap\n",
      "\n",
      "Finds the minimum of the given node .\n",
      "\n",
      "4\n",
      "void printEulerTour(int root, int N) { int index = 0; eulerTree(root, index); for (int i = 0; i < (2*N-1); i++) cout << Euler[i] << \" \"; }\n",
      "\n",
      "Function to print Euler Tour of tree\n",
      "\n",
      "Prints the outline of the Euler tree .\n",
      "\n",
      "5\n",
      "int max(int a, int b) { return a > b ? a : b; }\n",
      "\n",
      "Function to return the maximum of two elements\n",
      "\n",
      "Returns the maximum of two integers .\n",
      "\n",
      "6\n",
      "void countPairs(int* arr, int N) { vector<int> phi(1e5, 0); vector<int> ans(1e5, 0); preCalculate(phi, ans); for (int i = 0; i < N; ++i) { cout << ans[arr[i]] << \" \"; } }\n",
      "\n",
      "Function to count the number of non co-prime pairs for each query\n",
      "\n",
      "Counts the number of pairs\n",
      "\n",
      "7\n",
      "void printList(struct Node* head) { while (head != NULL) { printf(\"%d -> \", head->data); head = head->next; } cout << \"NULL\" << endl; }\n",
      "\n",
      "Display linked list.\n",
      "\n",
      "Prints list .\n",
      "\n",
      "8\n",
      "void reverse(char str[], int l, int h) { while (l < h) { swap(&str[l], &str[h]); l++; h--; } }\n",
      "\n",
      "A utility function to reverse a string str[l..h]\n",
      "\n",
      "Reverses the specified range of characters .\n",
      "\n",
      "9\n",
      "long long int minPlayer(long long int n, long long int k) { long long int num = ((power(k, n) - 1) + mod) % mod; long long int den = (power(k - 1, mod - 2) + mod) % mod; long long int ans = (((num * den) % mod) * k) % mod; return ans; }\n",
      "\n",
      "function to find the minimum required player\n",
      "\n",
      "Calculates the minimum number of players .\n",
      "\n",
      "10\n",
      "int findLargestSubtreeSumUtil(Node* root, int& ans) { if (root == NULL) return 0; int currSum = root->key + findLargestSubtreeSumUtil(root->left, ans) + findLargestSubtreeSumUtil(root->right, ans); ans = max(ans, currSum); return currSum; }\n",
      "\n",
      "Helper function to find largest subtree sum recursively.\n",
      "\n",
      "Returns the maximum size of the tree .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bleu4_score = bleu4_score(labels_pred, labels_act)\n",
    "print(\"The BLEU-4 score using the pre-trained model: {:.4f}.\".format(bleu4_score))\n",
    "print(\"\")\n",
    "print(\"Examples using pre-trained model\")\n",
    "for i, (code, label, prediction) in enumerate(zip(codes_act[10:20], labels_act[10:20], labels_pred[10:20])):\n",
    "    print(i+1)\n",
    "    print(code)\n",
    "    print(\"\")\n",
    "    print(label)\n",
    "    print(\"\")\n",
    "    print(prediction)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9456b01-547a-45c8-ab20-19ad9613b851",
   "metadata": {},
   "source": [
    "## Re-train model using C++ training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abfe00ce-49ee-4129-8984-726d2ba7bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for i, (codes, labels) in enumerate(data_loader):\n",
    "        # print(i)\n",
    "        codes_ids, codes_mask = convert_to_tokens(codes, tokenizer, True, MAX_LENGTH)\n",
    "        labels_ids, labels_mask = convert_to_tokens(labels, tokenizer, True, MAX_LENGTH)  \n",
    "        optimizer.zero_grad()\n",
    "        loss, _, _ = model(\n",
    "            source_ids = codes_ids,\n",
    "            source_mask = codes_mask,\n",
    "            target_ids = labels_ids,\n",
    "            target_mask = labels_mask)       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(float(loss.detach().cpu().mean().numpy()))\n",
    "\n",
    "    train_epoch_loss = np.mean(train_loss) \n",
    "    return train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5419fbd3-f2e5-42b0-a624-93bd5221c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, data_loader):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for i, (codes, labels) in enumerate(data_loader):\n",
    "        # print(i)\n",
    "        codes_ids, codes_mask = convert_to_tokens(codes, tokenizer, True, MAX_LENGTH)\n",
    "        labels_ids, labels_mask = convert_to_tokens(labels, tokenizer, True, MAX_LENGTH)               \n",
    "        loss, _, _ = model(\n",
    "            source_ids = codes_ids,\n",
    "            source_mask = codes_mask,\n",
    "            target_ids = labels_ids,\n",
    "            target_mask = labels_mask)\n",
    "        val_loss.append(float(loss.detach().cpu().mean().numpy()))\n",
    "\n",
    "    val_epoch_loss = np.mean(val_loss)\n",
    "    return val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d35be21-8676-4f87-8859-69b90715c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(model, best_para, loss):\n",
    "    if best_para[\"Loss\"] > loss:\n",
    "        best_para[\"Loss\"] = loss\n",
    "        model_state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "        model_state_dict = OrderedDict(model_state_dict)\n",
    "        best_para[\"Model\"] = model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fddd5ef-6bc9-4402-9282-3c46c49208ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], training loss: 3.353276.\n",
      "Epoch [0], validation loss: 2.971897.\n",
      "Epoch [1], training loss: 2.851434.\n",
      "Epoch [1], validation loss: 2.766125.\n",
      "Epoch [2], training loss: 2.618222.\n",
      "Epoch [2], validation loss: 2.651505.\n",
      "Epoch [3], training loss: 2.453126.\n",
      "Epoch [3], validation loss: 2.569354.\n",
      "Epoch [4], training loss: 2.319755.\n",
      "Epoch [4], validation loss: 2.499620.\n",
      "Epoch [5], training loss: 2.220275.\n",
      "Epoch [5], validation loss: 2.450132.\n",
      "Epoch [6], training loss: 2.112122.\n",
      "Epoch [6], validation loss: 2.415442.\n",
      "Epoch [7], training loss: 2.018943.\n",
      "Epoch [7], validation loss: 2.384732.\n",
      "Epoch [8], training loss: 1.948543.\n",
      "Epoch [8], validation loss: 2.359438.\n",
      "Epoch [9], training loss: 1.866240.\n",
      "Epoch [9], validation loss: 2.328853.\n",
      "Epoch [10], training loss: 1.793417.\n",
      "Epoch [10], validation loss: 2.311886.\n",
      "Epoch [11], training loss: 1.743383.\n",
      "Epoch [11], validation loss: 2.295072.\n",
      "Epoch [12], training loss: 1.675505.\n",
      "Epoch [12], validation loss: 2.278812.\n",
      "Epoch [13], training loss: 1.607648.\n",
      "Epoch [13], validation loss: 2.267526.\n",
      "Epoch [14], training loss: 1.558567.\n",
      "Epoch [14], validation loss: 2.258240.\n",
      "Epoch [15], training loss: 1.500742.\n",
      "Epoch [15], validation loss: 2.249485.\n",
      "Epoch [16], training loss: 1.448289.\n",
      "Epoch [16], validation loss: 2.245925.\n",
      "Epoch [17], training loss: 1.394040.\n",
      "Epoch [17], validation loss: 2.237749.\n",
      "Epoch [18], training loss: 1.347137.\n",
      "Epoch [18], validation loss: 2.236653.\n",
      "Epoch [19], training loss: 1.301857.\n",
      "Epoch [19], validation loss: 2.233478.\n",
      "Epoch [20], training loss: 1.261559.\n",
      "Epoch [20], validation loss: 2.227253.\n",
      "Epoch [21], training loss: 1.210990.\n",
      "Epoch [21], validation loss: 2.224730.\n",
      "Epoch [22], training loss: 1.173909.\n",
      "Epoch [22], validation loss: 2.221848.\n",
      "Epoch [23], training loss: 1.128462.\n",
      "Epoch [23], validation loss: 2.232473.\n",
      "Epoch [24], training loss: 1.086991.\n",
      "Epoch [24], validation loss: 2.227444.\n",
      "Epoch [25], training loss: 1.050591.\n",
      "Epoch [25], validation loss: 2.238729.\n",
      "Epoch [26], training loss: 1.006475.\n",
      "Epoch [26], validation loss: 2.243101.\n",
      "Epoch [27], training loss: 0.969737.\n",
      "Epoch [27], validation loss: 2.241645.\n",
      "Epoch [28], training loss: 0.936354.\n",
      "Epoch [28], validation loss: 2.248078.\n",
      "Epoch [29], training loss: 0.896612.\n",
      "Epoch [29], validation loss: 2.264024.\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 30\n",
    "LEARNING_RATE = 1e-5\n",
    "model_para = {\"Model\": None, \"Epoch\": 0}\n",
    "best_model_para = {\"Model\": None, \"Loss\": np.inf}\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCHES):\n",
    "    epoch_train_loss = train_model(model, train_loader)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(\"Epoch [{}], training loss: {:.6f}.\".format(epoch, epoch_train_loss))\n",
    "    epoch_val_loss = valid_model(model, val_loader)\n",
    "    val_loss.append(epoch_val_loss)\n",
    "    print(\"Epoch [{}], validation loss: {:.6f}.\".format(epoch, epoch_val_loss))\n",
    "    \n",
    "    epoch_state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "    epoch_state_dict = OrderedDict(epoch_state_dict)\n",
    "    para_file = \"./Epoch_CodeBERT_Para/\" + str(epoch) + \"_codeBERT_para.bin\"\n",
    "    torch.save(epoch_state_dict, para_file)\n",
    "    \n",
    "    if best_model_para[\"Loss\"] > epoch_val_loss:\n",
    "        best_model_para[\"Loss\"] = epoch_val_loss\n",
    "        state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "        state_dict = OrderedDict(state_dict)\n",
    "        best_model_para[\"Model\"] = state_dict\n",
    "# save the best model        \n",
    "torch.save(best_model_para[\"Model\"], \"./codeBERT_model_best.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c47c1372-717b-421b-b586-d29fa907143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = [8, 5])\n",
    "plt.plot(np.arange(len(train_loss[:])), train_loss[:], label='Training')\n",
    "plt.plot(np.arange(len(val_loss[:])), val_loss[:], label='Validation', linewidth=3)\n",
    "plt.ylabel('Loss',fontsize=14)\n",
    "plt.xlabel('Epoch',fontsize=14)\n",
    "plt.title(\"CodeBERT Model\", fontsize=14)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig('./codeBERT_model_loss.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9560781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_codeBERT_para.bin\n",
      "0.2414\n",
      "10_codeBERT_para.bin\n",
      "0.2731\n",
      "11_codeBERT_para.bin\n",
      "0.2816\n",
      "12_codeBERT_para.bin\n",
      "0.2799\n",
      "13_codeBERT_para.bin\n",
      "0.2863\n",
      "14_codeBERT_para.bin\n",
      "0.289\n",
      "15_codeBERT_para.bin\n",
      "0.2881\n",
      "16_codeBERT_para.bin\n",
      "0.2934\n",
      "17_codeBERT_para.bin\n",
      "0.292\n",
      "18_codeBERT_para.bin\n",
      "0.2953\n",
      "19_codeBERT_para.bin\n",
      "0.2929\n",
      "1_codeBERT_para.bin\n",
      "0.2525\n",
      "20_codeBERT_para.bin\n",
      "0.2951\n",
      "21_codeBERT_para.bin\n",
      "0.3043\n",
      "22_codeBERT_para.bin\n",
      "0.299\n",
      "23_codeBERT_para.bin\n",
      "0.3035\n",
      "24_codeBERT_para.bin\n",
      "0.3028\n",
      "25_codeBERT_para.bin\n",
      "0.3053\n",
      "26_codeBERT_para.bin\n",
      "0.3058\n",
      "27_codeBERT_para.bin\n",
      "0.3046\n",
      "28_codeBERT_para.bin\n",
      "0.308\n",
      "29_codeBERT_para.bin\n",
      "0.3071\n",
      "2_codeBERT_para.bin\n",
      "0.2531\n",
      "3_codeBERT_para.bin\n",
      "0.2586\n",
      "4_codeBERT_para.bin\n",
      "0.2665\n",
      "5_codeBERT_para.bin\n",
      "0.2683\n",
      "6_codeBERT_para.bin\n",
      "0.2766\n",
      "7_codeBERT_para.bin\n",
      "0.2785\n",
      "8_codeBERT_para.bin\n",
      "0.2806\n",
      "9_codeBERT_para.bin\n",
      "0.2807\n"
     ]
    }
   ],
   "source": [
    "# the path for model parameter\n",
    "arr = os.listdir('/home/jovyan/DeepLearningProject/Epoch_CodeBERT_Para')\n",
    "arr.sort()\n",
    "epoch_list = []\n",
    "val_bleu4_score = []\n",
    "\n",
    "for i in range(1, 31):\n",
    "    epoch_list.append(str(arr[i]))\n",
    "    print(arr[i])\n",
    "    pytorch_model = \"./Epoch_CodeBERT_Para/\" + arr[i]\n",
    "    checkpoint = torch.load(pytorch_model) # map_location='cpu'\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    re_codes_act = []\n",
    "    re_labels_act = []\n",
    "    re_labels_pred = []\n",
    "    \n",
    "    for _, (codes, labels) in enumerate(val_loader):\n",
    "        re_codes_act.extend(codes)\n",
    "        re_labels_act.extend(labels)\n",
    "        codes_ids, codes_mask = convert_to_tokens(codes, tokenizer, True, MAX_LENGTH)\n",
    "        tokens = model(source_ids=codes_ids, source_mask=codes_mask)\n",
    "        labels_output = tokens_to_labels(tokens, tokenizer)\n",
    "        re_labels_pred.extend(labels_output)\n",
    "    \n",
    "    def bleu4_score(labels_pred, labels_act):\n",
    "        (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "        bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "        return round(bleu4, 4)\n",
    "\n",
    "    re_bleu4_score = bleu4_score(re_labels_pred, re_labels_act)\n",
    "    val_bleu4_score.append(re_bleu4_score)\n",
    "    print(re_bleu4_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5421df6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>num_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_codeBERT_para.bin</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_codeBERT_para.bin</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_codeBERT_para.bin</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3_codeBERT_para.bin</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4_codeBERT_para.bin</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  epoch  bleu_score  num_epoch\n",
       "0   0_codeBERT_para.bin      0.2414          0\n",
       "11  1_codeBERT_para.bin      0.2525          1\n",
       "22  2_codeBERT_para.bin      0.2531          2\n",
       "23  3_codeBERT_para.bin      0.2586          3\n",
       "24  4_codeBERT_para.bin      0.2665          4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_epoch_list = epoch_list.copy()\n",
    "new_bleu4_score = val_bleu4_score.copy()\n",
    "num_epoch = [int(i.split('_', 1)[0]) for i in new_epoch_list]\n",
    "df_val_scores = pd.DataFrame(zip(new_epoch_list, new_bleu4_score, num_epoch), columns=['epoch','bleu_score','num_epoch'])\n",
    "df_val_scores.sort_values('num_epoch', ascending = True, inplace=True)\n",
    "df_val_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d35435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = [8, 5])\n",
    "plt.plot(df_val_scores['num_epoch'], df_val_scores['bleu_score'], label='Bleu4', linewidth=2, color = 'red')\n",
    "plt.ylabel('Score',fontsize=14)\n",
    "plt.xlabel('Epoch',fontsize=14)\n",
    "plt.title(\"CodeBERT Bleu Score\", fontsize=14)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig('./CodeBERT_bleu4_score.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ec07d-eb06-43c1-98e7-d56bc776ed1f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9692995b-6d4d-4706-b98c-9feea9cf6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the best model \n",
    "model.load_state_dict(best_model_para[\"Model\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e568cc6-529b-4130-93a3-bc83361fd8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# using pre-trained model to make a test\n",
    "model.eval()\n",
    "re_codes_act = []\n",
    "re_labels_act = []\n",
    "re_labels_pred = []\n",
    "for i, (codes, labels) in enumerate(test_loader):\n",
    "    re_codes_act.extend(codes)\n",
    "    re_labels_act.extend(labels)\n",
    "    codes_ids, codes_mask = convert_to_tokens(codes, tokenizer, True, MAX_LENGTH)\n",
    "    tokens = model(source_ids=codes_ids, source_mask=codes_mask)\n",
    "    labels_output = tokens_to_labels(tokens, tokenizer)\n",
    "    re_labels_pred.extend(labels_output)\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    # if i == 5:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "406a0fc4-d38f-4eb8-9d18-c202545e5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu4_score(labels_pred, labels_act):\n",
    "    (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "    bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "    return round(bleu4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5cc861f-81ce-4bb4-9929-7257c23ae875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU-4 score using the retrained model: 0.3172.\n",
      "\n",
      "Examples after retraining model\n",
      "1\n",
      "unsigned int aModM(string s, unsigned int mod) { unsigned int number = 0; for (unsigned int i = 0; i < s.length(); i++) { number = (number*10 + (s[i] - '0')); number %= mod; } return number; }\n",
      "\n",
      "utility function to calculate a%m\n",
      "\n",
      "function to calculate a mod m\n",
      "\n",
      "2\n",
      "int nextChar(int freq[], int dist[]) { int max = INT_MIN; for (int i = 0; i < MAX_CHAR; i++) if (dist[i] <= 0 && freq[i] > 0 && (max == INT_MIN || freq[i] > freq[max])) max = i; return max; }\n",
      "\n",
      "The function returns next eligible character with maximum frequency (Greedy!!) and zero or negative distance\n",
      "\n",
      "Function to return the next character\n",
      "\n",
      "3\n",
      "void find_min(struct node* mini) { cout << \"min of heap is: \" << mini->key << endl; }\n",
      "\n",
      "Function to find min node in the heap\n",
      "\n",
      "Function to find the min of node\n",
      "\n",
      "4\n",
      "void printEulerTour(int root, int N) { int index = 0; eulerTree(root, index); for (int i = 0; i < (2*N-1); i++) cout << Euler[i] << \" \"; }\n",
      "\n",
      "Function to print Euler Tour of tree\n",
      "\n",
      "Function to print Euler Tour\n",
      "\n",
      "5\n",
      "int max(int a, int b) { return a > b ? a : b; }\n",
      "\n",
      "Function to return the maximum of two elements\n",
      "\n",
      "A utility function to find maximum of two integers\n",
      "\n",
      "6\n",
      "void countPairs(int* arr, int N) { vector<int> phi(1e5, 0); vector<int> ans(1e5, 0); preCalculate(phi, ans); for (int i = 0; i < N; ++i) { cout << ans[arr[i]] << \" \"; } }\n",
      "\n",
      "Function to count the number of non co-prime pairs for each query\n",
      "\n",
      "Function to print the count of valid pairs\n",
      "\n",
      "7\n",
      "void printList(struct Node* head) { while (head != NULL) { printf(\"%d -> \", head->data); head = head->next; } cout << \"NULL\" << endl; }\n",
      "\n",
      "Display linked list.\n",
      "\n",
      "A utility function to print a linked list\n",
      "\n",
      "8\n",
      "void reverse(char str[], int l, int h) { while (l < h) { swap(&str[l], &str[h]); l++; h--; } }\n",
      "\n",
      "A utility function to reverse a string str[l..h]\n",
      "\n",
      "Function to reverse the characters of the string\n",
      "\n",
      "9\n",
      "long long int minPlayer(long long int n, long long int k) { long long int num = ((power(k, n) - 1) + mod) % mod; long long int den = (power(k - 1, mod - 2) + mod) % mod; long long int ans = (((num * den) % mod) * k) % mod; return ans; }\n",
      "\n",
      "function to find the minimum required player\n",
      "\n",
      "Function to return the required player\n",
      "\n",
      "10\n",
      "int findLargestSubtreeSumUtil(Node* root, int& ans) { if (root == NULL) return 0; int currSum = root->key + findLargestSubtreeSumUtil(root->left, ans) + findLargestSubtreeSumUtil(root->right, ans); ans = max(ans, currSum); return currSum; }\n",
      "\n",
      "Helper function to find largest subtree sum recursively.\n",
      "\n",
      "Function to find the largest subtree sum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re_bleu4_score = bleu4_score(re_labels_pred, re_labels_act)\n",
    "print(\"The BLEU-4 score using the retrained model: {:.4f}.\".format(re_bleu4_score))\n",
    "print(\"\")\n",
    "print(\"Examples after retraining model\")\n",
    "for i, (code, label, prediction) in enumerate(zip(re_codes_act[10:20], re_labels_act[10:20], re_labels_pred[10:20])):\n",
    "    print(i+1)\n",
    "    print(code)\n",
    "    print(\"\")\n",
    "    print(label)\n",
    "    print(\"\")\n",
    "    print(prediction)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e2638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy37",
   "language": "python",
   "name": "newpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
