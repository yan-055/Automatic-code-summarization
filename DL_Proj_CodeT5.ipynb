{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb65131-d123-492d-b6ef-85eeb9ed1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/newpy37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy as cp\n",
    "import renew_bleu\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4990167-62a4-48ff-ae5a-4ea4aa2749a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of C++ code files is: 9289\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "with open(\"selected_files.txt\", \"r\") as f: # selected_files\n",
    "    for l in f.readlines():\n",
    "        filenames.append(l.strip())\n",
    "num_of_files = len(filenames)\n",
    "print(\"Number of C++ code files is: {}\".format(num_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a75237-74bd-4b03-939e-d0487c632781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeDataset (Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        func = \"\"\n",
    "        func_file = \"func/{}.cpp\".format(self.filenames[index])\n",
    "        with open(func_file, \"r\") as f:\n",
    "            for l in f.readlines():\n",
    "                func += l\n",
    "        func = \" \".join(func.replace('\\n', \" \").split())\n",
    "        # print(len(func))\n",
    "\n",
    "        label = \"\"\n",
    "        label_file = \"label/{}.text\".format(self.filenames[index])\n",
    "        with open(label_file, \"r\") as f:\n",
    "            for l in f.readlines():\n",
    "                label += l\n",
    "        label = label.replace('//', \" \").replace('/*', \" \").replace('*/', \" \").replace('\\n', \" \")\n",
    "        label = \" \".join(label.split())\n",
    "        # print(len(label))\n",
    "        \n",
    "        return func, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3c448d-6bb5-4d5b-b182-7a1eb0e7bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 7431\n",
      "('void print(int mat[][MAX], int n, int m) { for (int i = 0; i < n; i++) { for (int j = 0; j < m; j++) { cout << mat[i][j] << \" \"; } cout << endl; } }', 'Function to print the resultant matrix')\n",
      "\n",
      "validation sample size: 928\n",
      "('unsigned int doublefactorial(unsigned int n) { if (n == 0 || n==1) return 1; return n*doublefactorial(n-2); }', 'function to find double factorial of given number')\n",
      "\n",
      "Test sample size: 930\n",
      "('void push(Node** head_ref, int new_data) { Node* new_node = new Node(); new_node->data = new_data; new_node->next = (*head_ref); (*head_ref) = new_node; }', 'function to add a new node at the beginning of the list')\n"
     ]
    }
   ],
   "source": [
    "size_t = int(num_of_files * 0.8)\n",
    "size_val = int(num_of_files * 0.1)\n",
    "train_data = CodeDataset(filenames[:5])\n",
    "train_data = CodeDataset(filenames[:size_t])\n",
    "val_data = CodeDataset(filenames[size_t:size_t+size_val])\n",
    "test_data = CodeDataset(filenames[size_t+size_val:])\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "print(\"Training sample size: {}\".format(size_t))\n",
    "print(train_data[1])\n",
    "print(\"\")\n",
    "print(\"validation sample size: {}\".format(size_val))\n",
    "print(val_data[1])\n",
    "print(\"\")\n",
    "print(\"Test sample size: {}\".format(num_of_files-size_t-size_val))\n",
    "print(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b6e874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627dc953-27e6-46f0-97c0-35dd44f64b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = []\n",
    "for func, label in train_loader:\n",
    "    for codes in func:\n",
    "        token_length.append(len(tokenizer(codes)[\"input_ids\"]))\n",
    "\n",
    "mean_length = np.mean(token_length)\n",
    "min_length = min(token_length)\n",
    "max_length = max(token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e746182-0a3d-4eda-9043-d9aacfe97c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of token length: 60.36495761001211\n",
      "Min of token length: 7\n",
      "Max of token length: 135\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Mean of token length: {}\".format(mean_length))\n",
    "print(\"Min of token length: {}\".format(min_length))\n",
    "print(\"Max of token length: {}\".format(max_length))\n",
    "bins = np.arange(min_length, max_length, 50) \n",
    "plt.xlim([min_length-5, max_length+5])\n",
    "plt.hist(token_length, bins=bins, alpha=0.8)\n",
    "plt.title('Histogram of token length')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd7acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf23f09-1afc-4620-8e71-47385da8dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/newpy37/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# using pre-trained model to make a test\n",
    "# model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')\n",
    "model.eval()\n",
    "codes_act = []\n",
    "labels_act = []\n",
    "labels_pred = []\n",
    "\n",
    "\n",
    "for i, (func, labels) in enumerate(test_loader):      \n",
    "    for codes in func:\n",
    "        codes_act.append(codes)\n",
    "        inputs = tokenizer(\n",
    "            codes,\n",
    "            max_length=MAX_LENGTH,\n",
    "            pad_to_max_length=True,\n",
    "            truncation = True,\n",
    "            return_tensors=\"pt\")\n",
    "        inputs.to(device)\n",
    "        \n",
    "        input_ids = inputs['input_ids']\n",
    "        # attention_mask = inputs['attention_mask']\n",
    "            \n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids, \n",
    "            # attention_mask=attention_mask, \n",
    "            max_length=128) \n",
    "            \n",
    "        labels_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)            \n",
    "        labels_pred.append(labels_output)\n",
    "\n",
    "    \n",
    "    for label in labels:\n",
    "        labels_act.append(label)\n",
    "        \n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2956e5-751d-4c2c-a881-c1eff6ce6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu4_score(labels_pred, labels_act):\n",
    "    (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "    bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "    return round(bleu4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b190325-9b4a-4c93-97bc-707ffef8699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU-4 score using the pre-trained model: 0.0054.\n",
      "\n",
      "Examples using pre-trained model\n",
      "1\n",
      "unsigned int aModM(string s, unsigned int mod) { unsigned int number = 0; for (unsigned int i = 0; i < s.length(); i++) { number = (number*10 + (s[i] - '0')); number %= mod; } return number; }\n",
      "\n",
      "utility function to calculate a%m\n",
      "\n",
      "int\n",
      "\n",
      "2\n",
      "int nextChar(int freq[], int dist[]) { int max = INT_MIN; for (int i = 0; i < MAX_CHAR; i++) if (dist[i] <= 0 && freq[i] > 0 && (max == INT_MIN || freq[i] > freq[max])) max = i; return max; }\n",
      "\n",
      "The function returns next eligible character with maximum frequency (Greedy!!) and zero or negative distance\n",
      "\n",
      "int\n",
      "\n",
      "3\n",
      "void find_min(struct node* mini) { cout << \"min of heap is: \" << mini->key << endl; }\n",
      "\n",
      "Function to find min node in the heap\n",
      "\n",
      "mini\n",
      "\n",
      "4\n",
      "void printEulerTour(int root, int N) { int index = 0; eulerTree(root, index); for (int i = 0; i < (2*N-1); i++) cout << Euler[i] << \" \"; }\n",
      "\n",
      "Function to print Euler Tour of tree\n",
      "\n",
      "index++\n",
      "\n",
      "5\n",
      "int max(int a, int b) { return a > b ? a : b; }\n",
      "\n",
      "Function to return the maximum of two elements\n",
      "\n",
      "int\n",
      "\n",
      "6\n",
      "void countPairs(int* arr, int N) { vector<int> phi(1e5, 0); vector<int> ans(1e5, 0); preCalculate(phi, ans); for (int i = 0; i < N; ++i) { cout << ans[arr[i]] << \" \"; } }\n",
      "\n",
      "Function to count the number of non co-prime pairs for each query\n",
      "\n",
      "phi\n",
      "\n",
      "7\n",
      "void printList(struct Node* head) { while (head != NULL) { printf(\"%d -> \", head->data); head = head->next; } cout << \"NULL\" << endl; }\n",
      "\n",
      "Display linked list.\n",
      "\n",
      "head;\n",
      "\n",
      "8\n",
      "void reverse(char str[], int l, int h) { while (l < h) { swap(&str[l], &str[h]); l++; h--; } }\n",
      "\n",
      "A utility function to reverse a string str[l..h]\n",
      "\n",
      "int\n",
      "\n",
      "9\n",
      "long long int minPlayer(long long int n, long long int k) { long long int num = ((power(k, n) - 1) + mod) % mod; long long int den = (power(k - 1, mod - 2) + mod) % mod; long long int ans = (((num * den) % mod) * k) % mod; return ans; }\n",
      "\n",
      "function to find the minimum required player\n",
      "\n",
      "mod\n",
      "\n",
      "10\n",
      "int findLargestSubtreeSumUtil(Node* root, int& ans) { if (root == NULL) return 0; int currSum = root->key + findLargestSubtreeSumUtil(root->left, ans) + findLargestSubtreeSumUtil(root->right, ans); ans = max(ans, currSum); return currSum; }\n",
      "\n",
      "Helper function to find largest subtree sum recursively.\n",
      "\n",
      "root->key\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bleu4_score = bleu4_score(labels_pred, labels_act)\n",
    "print(\"The BLEU-4 score using the pre-trained model: {:.4f}.\".format(bleu4_score))\n",
    "print(\"\")\n",
    "print(\"Examples using pre-trained model\")\n",
    "for i, (code, label, prediction) in enumerate(zip(codes_act[10:20], labels_act[10:20], labels_pred[10:20])):\n",
    "    print(i+1)\n",
    "    print(code)\n",
    "    print(\"\")\n",
    "    print(label)\n",
    "    print(\"\")\n",
    "    print(prediction)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9456b01-547a-45c8-ab20-19ad9613b851",
   "metadata": {},
   "source": [
    "## Re-train model using C++ training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7569d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tokens(codes, tokenizer, truncation, max_length, pad_to_max=True):\n",
    "    tokens = tokenizer(codes, truncation=truncation, max_length=max_length, pad_to_max_length=pad_to_max, return_tensors=\"pt\")\n",
    "    input_ids = torch.tensor(tokens[\"input_ids\"])\n",
    "    return input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bda12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader):\n",
    "    # bar = tqdm(data_loader, total=len(data_loader), desc=\"Training\")\n",
    "    model.train()\n",
    "    # nb_tr_examples = 0\n",
    "    nb_tr_steps, tr_loss = 0, 0\n",
    "    for i, (source_ids, target_ids) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        source_ids = convert_to_tokens(source_ids, tokenizer, True, MAX_LENGTH)\n",
    "        target_ids = convert_to_tokens(target_ids, tokenizer, True, MAX_LENGTH)\n",
    "        # print(source_ids)\n",
    "        source_mask = source_ids.ne(tokenizer.pad_token_id)\n",
    "        target_mask = target_ids.ne(tokenizer.pad_token_id)\n",
    "        # print(source_mask)\n",
    "        \n",
    "        outputs = model(input_ids=source_ids, attention_mask=source_mask,\n",
    "                       labels=target_ids, decoder_attention_mask=target_mask)    \n",
    "    \n",
    "        loss = outputs.loss   \n",
    "        loss = loss.mean()\n",
    "        \n",
    "        tr_loss += loss.item() \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        nb_tr_steps += 1        \n",
    " \n",
    "    train_epoch_loss = tr_loss / nb_tr_steps \n",
    "    return train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5419fbd3-f2e5-42b0-a624-93bd5221c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, batch_num = 0, 0\n",
    "    # for batch in tqdm(data_loader, total=len(data_loader), desc=\"Validation\"):\n",
    "    for i, (source_ids, target_ids) in enumerate(data_loader):\n",
    "      \n",
    "        source_ids = convert_to_tokens(source_ids, tokenizer, True, MAX_LENGTH)\n",
    "        target_ids = convert_to_tokens(target_ids, tokenizer, True, MAX_LENGTH)\n",
    "        # print(source_ids)\n",
    "        source_mask = source_ids.ne(tokenizer.pad_token_id)\n",
    "        target_mask = target_ids.ne(tokenizer.pad_token_id)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=source_ids, attention_mask=source_mask,\n",
    "                            labels=target_ids, decoder_attention_mask=target_mask)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            loss = loss.mean()\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        batch_num += 1\n",
    "         \n",
    "    val_epoch_loss = eval_loss / batch_num\n",
    "\n",
    "    return val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d35be21-8676-4f87-8859-69b90715c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(model, best_para, loss):\n",
    "    if best_para[\"Loss\"] > loss:\n",
    "        best_para[\"Loss\"] = loss\n",
    "        model_state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "        model_state_dict = OrderedDict(model_state_dict)\n",
    "        best_para[\"Model\"] = model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fddd5ef-6bc9-4402-9282-3c46c49208ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/newpy37/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/newpy37/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], training loss: 0.567007.\n",
      "Epoch [0], validation loss: 0.349210.\n",
      "Epoch [1], training loss: 0.356867.\n",
      "Epoch [1], validation loss: 0.321003.\n",
      "Epoch [2], training loss: 0.334879.\n",
      "Epoch [2], validation loss: 0.308651.\n",
      "Epoch [3], training loss: 0.323697.\n",
      "Epoch [3], validation loss: 0.300306.\n",
      "Epoch [4], training loss: 0.314457.\n",
      "Epoch [4], validation loss: 0.293913.\n",
      "Epoch [5], training loss: 0.306984.\n",
      "Epoch [5], validation loss: 0.288588.\n",
      "Epoch [6], training loss: 0.300318.\n",
      "Epoch [6], validation loss: 0.284537.\n",
      "Epoch [7], training loss: 0.294849.\n",
      "Epoch [7], validation loss: 0.280661.\n",
      "Epoch [8], training loss: 0.289787.\n",
      "Epoch [8], validation loss: 0.277630.\n",
      "Epoch [9], training loss: 0.284986.\n",
      "Epoch [9], validation loss: 0.274578.\n",
      "Epoch [10], training loss: 0.281672.\n",
      "Epoch [10], validation loss: 0.272200.\n",
      "Epoch [11], training loss: 0.275898.\n",
      "Epoch [11], validation loss: 0.269643.\n",
      "Epoch [12], training loss: 0.272593.\n",
      "Epoch [12], validation loss: 0.267849.\n",
      "Epoch [13], training loss: 0.268610.\n",
      "Epoch [13], validation loss: 0.265757.\n",
      "Epoch [14], training loss: 0.265603.\n",
      "Epoch [14], validation loss: 0.263730.\n",
      "Epoch [15], training loss: 0.262831.\n",
      "Epoch [15], validation loss: 0.262080.\n",
      "Epoch [16], training loss: 0.258994.\n",
      "Epoch [16], validation loss: 0.260789.\n",
      "Epoch [17], training loss: 0.255528.\n",
      "Epoch [17], validation loss: 0.258905.\n",
      "Epoch [18], training loss: 0.252934.\n",
      "Epoch [18], validation loss: 0.257777.\n",
      "Epoch [19], training loss: 0.249743.\n",
      "Epoch [19], validation loss: 0.256383.\n",
      "Epoch [20], training loss: 0.246452.\n",
      "Epoch [20], validation loss: 0.254920.\n",
      "Epoch [21], training loss: 0.245428.\n",
      "Epoch [21], validation loss: 0.253857.\n",
      "Epoch [22], training loss: 0.242146.\n",
      "Epoch [22], validation loss: 0.253067.\n",
      "Epoch [23], training loss: 0.240372.\n",
      "Epoch [23], validation loss: 0.251872.\n",
      "Epoch [24], training loss: 0.237780.\n",
      "Epoch [24], validation loss: 0.251264.\n",
      "Epoch [25], training loss: 0.234945.\n",
      "Epoch [25], validation loss: 0.250414.\n",
      "Epoch [26], training loss: 0.232766.\n",
      "Epoch [26], validation loss: 0.249083.\n",
      "Epoch [27], training loss: 0.230165.\n",
      "Epoch [27], validation loss: 0.248141.\n",
      "Epoch [28], training loss: 0.229276.\n",
      "Epoch [28], validation loss: 0.247460.\n",
      "Epoch [29], training loss: 0.226071.\n",
      "Epoch [29], validation loss: 0.246484.\n",
      "Epoch [30], training loss: 0.224875.\n",
      "Epoch [30], validation loss: 0.246176.\n",
      "Epoch [31], training loss: 0.221519.\n",
      "Epoch [31], validation loss: 0.245495.\n",
      "Epoch [32], training loss: 0.219686.\n",
      "Epoch [32], validation loss: 0.244932.\n",
      "Epoch [33], training loss: 0.218626.\n",
      "Epoch [33], validation loss: 0.244004.\n",
      "Epoch [34], training loss: 0.215014.\n",
      "Epoch [34], validation loss: 0.244148.\n",
      "Epoch [35], training loss: 0.213879.\n",
      "Epoch [35], validation loss: 0.243211.\n",
      "Epoch [36], training loss: 0.212453.\n",
      "Epoch [36], validation loss: 0.242814.\n",
      "Epoch [37], training loss: 0.209871.\n",
      "Epoch [37], validation loss: 0.241895.\n",
      "Epoch [38], training loss: 0.208387.\n",
      "Epoch [38], validation loss: 0.241862.\n",
      "Epoch [39], training loss: 0.206915.\n",
      "Epoch [39], validation loss: 0.241708.\n",
      "Epoch [40], training loss: 0.205644.\n",
      "Epoch [40], validation loss: 0.241220.\n",
      "Epoch [41], training loss: 0.203214.\n",
      "Epoch [41], validation loss: 0.240492.\n",
      "Epoch [42], training loss: 0.201958.\n",
      "Epoch [42], validation loss: 0.239859.\n",
      "Epoch [43], training loss: 0.201239.\n",
      "Epoch [43], validation loss: 0.239262.\n",
      "Epoch [44], training loss: 0.198780.\n",
      "Epoch [44], validation loss: 0.238988.\n",
      "Epoch [45], training loss: 0.198040.\n",
      "Epoch [45], validation loss: 0.238881.\n",
      "Epoch [46], training loss: 0.195738.\n",
      "Epoch [46], validation loss: 0.238480.\n",
      "Epoch [47], training loss: 0.195067.\n",
      "Epoch [47], validation loss: 0.238257.\n",
      "Epoch [48], training loss: 0.192957.\n",
      "Epoch [48], validation loss: 0.238638.\n",
      "Epoch [49], training loss: 0.191316.\n",
      "Epoch [49], validation loss: 0.237927.\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 50\n",
    "LEARNING_RATE = 1e-5\n",
    "model_para = {\"Model\": None, \"Epoch\": 0}\n",
    "best_model_para = {\"Model\": None, \"Loss\": np.inf}\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCHES):\n",
    "    epoch_train_loss = train_model(model, train_loader)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(\"Epoch [{}], training loss: {:.6f}.\".format(epoch, epoch_train_loss))\n",
    "    epoch_val_loss = valid_model(model, val_loader)\n",
    "    val_loss.append(epoch_val_loss)\n",
    "    print(\"Epoch [{}], validation loss: {:.6f}.\".format(epoch, epoch_val_loss))\n",
    "    \n",
    "    epoch_state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "    epoch_state_dict = OrderedDict(epoch_state_dict)\n",
    "    para_file = \"./Epoch_CodeT5_Para/\" + str(epoch) + \"_codeT5_para.bin\"\n",
    "    torch.save(epoch_state_dict, para_file)\n",
    "    \n",
    "    if best_model_para[\"Loss\"] > epoch_val_loss:\n",
    "        best_model_para[\"Loss\"] = epoch_val_loss\n",
    "        state_dict = {key:value.to('cpu') for key, value in model.state_dict().items()}\n",
    "        state_dict = OrderedDict(state_dict)\n",
    "        best_model_para[\"Model\"] = state_dict\n",
    "# save the best model        \n",
    "torch.save(best_model_para[\"Model\"], \"./codeT5_model_best.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47c1372-717b-421b-b586-d29fa907143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = [8, 5])\n",
    "plt.plot(np.arange(len(train_loss[:])), train_loss[:], label='Training')\n",
    "plt.plot(np.arange(len(val_loss[:])), val_loss[:], label='Validation', linewidth=3)\n",
    "plt.ylabel('Loss',fontsize=14)\n",
    "plt.xlabel('Epoch',fontsize=14)\n",
    "plt.title(\"CodeT5 Model\", fontsize=14)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig('./CodeT5_model_loss.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6618460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_codeT5_para.bin\n",
      "0.1932\n",
      "10_codeT5_para.bin\n",
      "0.2577\n",
      "11_codeT5_para.bin\n",
      "0.26\n",
      "12_codeT5_para.bin\n",
      "0.2614\n",
      "13_codeT5_para.bin\n",
      "0.2644\n",
      "14_codeT5_para.bin\n",
      "0.2657\n",
      "15_codeT5_para.bin\n",
      "0.2656\n",
      "16_codeT5_para.bin\n",
      "0.267\n",
      "17_codeT5_para.bin\n",
      "0.2668\n",
      "18_codeT5_para.bin\n",
      "0.2681\n",
      "19_codeT5_para.bin\n",
      "0.2714\n",
      "1_codeT5_para.bin\n",
      "0.2398\n",
      "20_codeT5_para.bin\n",
      "0.2689\n",
      "21_codeT5_para.bin\n",
      "0.272\n",
      "22_codeT5_para.bin\n",
      "0.2733\n",
      "23_codeT5_para.bin\n",
      "0.2756\n",
      "24_codeT5_para.bin\n",
      "0.2754\n",
      "25_codeT5_para.bin\n",
      "0.2751\n",
      "26_codeT5_para.bin\n",
      "0.2779\n",
      "27_codeT5_para.bin\n",
      "0.2768\n",
      "28_codeT5_para.bin\n",
      "0.2798\n",
      "29_codeT5_para.bin\n",
      "0.281\n",
      "2_codeT5_para.bin\n",
      "0.2402\n",
      "30_codeT5_para.bin\n",
      "0.2815\n",
      "31_codeT5_para.bin\n",
      "0.2821\n",
      "32_codeT5_para.bin\n",
      "0.2842\n",
      "33_codeT5_para.bin\n",
      "0.2818\n",
      "34_codeT5_para.bin\n",
      "0.2834\n",
      "35_codeT5_para.bin\n",
      "0.2839\n",
      "36_codeT5_para.bin\n",
      "0.2837\n",
      "37_codeT5_para.bin\n",
      "0.2863\n",
      "38_codeT5_para.bin\n",
      "0.2867\n",
      "39_codeT5_para.bin\n",
      "0.2835\n",
      "3_codeT5_para.bin\n",
      "0.2437\n",
      "40_codeT5_para.bin\n",
      "0.2849\n",
      "41_codeT5_para.bin\n",
      "0.2854\n",
      "42_codeT5_para.bin\n",
      "0.2858\n",
      "43_codeT5_para.bin\n",
      "0.2903\n",
      "44_codeT5_para.bin\n",
      "0.2895\n",
      "45_codeT5_para.bin\n",
      "0.2909\n",
      "46_codeT5_para.bin\n",
      "0.2873\n",
      "47_codeT5_para.bin\n",
      "0.2915\n",
      "48_codeT5_para.bin\n",
      "0.2882\n",
      "49_codeT5_para.bin\n",
      "0.2882\n",
      "4_codeT5_para.bin\n",
      "0.247\n",
      "5_codeT5_para.bin\n",
      "0.2493\n",
      "6_codeT5_para.bin\n",
      "0.2531\n",
      "7_codeT5_para.bin\n",
      "0.2542\n",
      "8_codeT5_para.bin\n",
      "0.2554\n",
      "9_codeT5_para.bin\n",
      "0.2574\n"
     ]
    }
   ],
   "source": [
    "# the path for model parameter\n",
    "arr = os.listdir('/home/jovyan/DeepLearningProject/Epoch_CodeT5_Para') \n",
    "arr.sort()\n",
    "epoch_list = []\n",
    "val_bleu4_score = []\n",
    "for i in range(1, 51):\n",
    "    epoch_list.append(str(arr[i]))\n",
    "    print(arr[i])\n",
    "    pytorch_model = \"./Epoch_CodeT5_Para/\" + arr[i]\n",
    "    checkpoint = torch.load(pytorch_model, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    re_codes_act = []\n",
    "    re_labels_act = []\n",
    "    re_labels_pred = []\n",
    "    \n",
    "    for _, (func, labels) in enumerate(val_loader):      \n",
    "        for codes in func:\n",
    "            re_codes_act.append(codes)\n",
    "            inputs = tokenizer(\n",
    "                codes,\n",
    "                max_length=MAX_LENGTH,\n",
    "                pad_to_max_length=True,\n",
    "                truncation = True,\n",
    "                return_tensors=\"pt\")\n",
    "            inputs.to(device)\n",
    "\n",
    "            input_ids = inputs['input_ids']\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,  \n",
    "                max_length=128) \n",
    "\n",
    "            labels_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)            \n",
    "            re_labels_pred.append(labels_output)\n",
    "\n",
    "        for label in labels:\n",
    "            re_labels_act.append(label)\n",
    "     \n",
    "    \n",
    "    def bleu4_score(labels_pred, labels_act):\n",
    "        (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "        bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "        return round(bleu4, 4)\n",
    "\n",
    "    re_bleu4_score = bleu4_score(re_labels_pred, re_labels_act)\n",
    "    val_bleu4_score.append(re_bleu4_score)\n",
    "    print(re_bleu4_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cecb1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>num_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_codeT5_para.bin</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_codeT5_para.bin</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_codeT5_para.bin</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3_codeT5_para.bin</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4_codeT5_para.bin</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch  bleu_score  num_epoch\n",
       "0   0_codeT5_para.bin      0.1932          0\n",
       "11  1_codeT5_para.bin      0.2398          1\n",
       "22  2_codeT5_para.bin      0.2402          2\n",
       "33  3_codeT5_para.bin      0.2437          3\n",
       "44  4_codeT5_para.bin      0.2470          4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_epoch_list = epoch_list.copy()\n",
    "new_bleu4_score = val_bleu4_score.copy()\n",
    "num_epoch = [int(i.split('_', 1)[0]) for i in new_epoch_list]\n",
    "df_val_scores = pd.DataFrame(zip(new_epoch_list, new_bleu4_score, num_epoch), columns=['epoch','bleu_score','num_epoch'])\n",
    "df_val_scores.sort_values('num_epoch', ascending = True, inplace=True)\n",
    "df_val_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08a2c793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize = [8, 5])\n",
    "plt.plot(df_val_scores['num_epoch'], df_val_scores['bleu_score'], label='Bleu4', linewidth=2, color = 'red')\n",
    "plt.ylabel('Score',fontsize=14)\n",
    "plt.xlabel('Epoch',fontsize=14)\n",
    "plt.title(\"CodeT5 Bleu Score\", fontsize=14)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig('./CodeT5_bleu4_score.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ec07d-eb06-43c1-98e7-d56bc776ed1f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9692995b-6d4d-4706-b98c-9feea9cf6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the best model \n",
    "model.load_state_dict(best_model_para[\"Model\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e568cc6-529b-4130-93a3-bc83361fd8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# using fine-tuning model to make a test\n",
    "model.eval()\n",
    "re_codes_act = []\n",
    "re_labels_act = []\n",
    "re_labels_pred = []\n",
    "\n",
    "for i, (func, labels) in enumerate(test_loader):      \n",
    "    for codes in func:\n",
    "        re_codes_act.append(codes)\n",
    "        inputs = tokenizer(\n",
    "            codes,\n",
    "            max_length=MAX_LENGTH,\n",
    "            pad_to_max_length=True,\n",
    "            truncation = True,\n",
    "            return_tensors=\"pt\")\n",
    "        inputs.to(device)\n",
    "        \n",
    "        input_ids = inputs['input_ids']\n",
    "            \n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,  \n",
    "            max_length=128) \n",
    "        \n",
    "        labels_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)            \n",
    "        re_labels_pred.append(labels_output)\n",
    "\n",
    "    \n",
    "    for label in labels:\n",
    "        re_labels_act.append(label)\n",
    "        \n",
    "    if i%10==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406a0fc4-d38f-4eb8-9d18-c202545e5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu4_score(labels_pred, labels_act):\n",
    "    (map_act, map_pred) = renew_bleu.mapping(labels_act, labels_pred)\n",
    "    bleu4 = renew_bleu.bleuFromMaps(map_act, map_pred)[0]\n",
    "    return round(bleu4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5cc861f-81ce-4bb4-9929-7257c23ae875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BLEU-4 score using the retrained model: 0.3017.\n",
      "\n",
      "Examples after retraining model\n",
      "1\n",
      "unsigned int aModM(string s, unsigned int mod) { unsigned int number = 0; for (unsigned int i = 0; i < s.length(); i++) { number = (number*10 + (s[i] - '0')); number %= mod; } return number; }\n",
      "\n",
      "utility function to calculate a%m\n",
      "\n",
      "Function to calculate the mod M\n",
      "\n",
      "2\n",
      "int nextChar(int freq[], int dist[]) { int max = INT_MIN; for (int i = 0; i < MAX_CHAR; i++) if (dist[i] <= 0 && freq[i] > 0 && (max == INT_MIN || freq[i] > freq[max])) max = i; return max; }\n",
      "\n",
      "The function returns next eligible character with maximum frequency (Greedy!!) and zero or negative distance\n",
      "\n",
      "Function to find the next character in the array\n",
      "\n",
      "3\n",
      "void find_min(struct node* mini) { cout << \"min of heap is: \" << mini->key << endl; }\n",
      "\n",
      "Function to find min node in the heap\n",
      "\n",
      "Function to find the minimum node in the heap\n",
      "\n",
      "4\n",
      "void printEulerTour(int root, int N) { int index = 0; eulerTree(root, index); for (int i = 0; i < (2*N-1); i++) cout << Euler[i] << \" \"; }\n",
      "\n",
      "Function to print Euler Tour of tree\n",
      "\n",
      "Function to print the Euler Tour of the tree\n",
      "\n",
      "5\n",
      "int max(int a, int b) { return a > b ? a : b; }\n",
      "\n",
      "Function to return the maximum of two elements\n",
      "\n",
      "Function to return maximum of two integers\n",
      "\n",
      "6\n",
      "void countPairs(int* arr, int N) { vector<int> phi(1e5, 0); vector<int> ans(1e5, 0); preCalculate(phi, ans); for (int i = 0; i < N; ++i) { cout << ans[arr[i]] << \" \"; } }\n",
      "\n",
      "Function to count the number of non co-prime pairs for each query\n",
      "\n",
      "Function to count the number of pairs\n",
      "\n",
      "7\n",
      "void printList(struct Node* head) { while (head != NULL) { printf(\"%d -> \", head->data); head = head->next; } cout << \"NULL\" << endl; }\n",
      "\n",
      "Display linked list.\n",
      "\n",
      "Function to print the linked list\n",
      "\n",
      "8\n",
      "void reverse(char str[], int l, int h) { while (l < h) { swap(&str[l], &str[h]); l++; h--; } }\n",
      "\n",
      "A utility function to reverse a string str[l..h]\n",
      "\n",
      "Function to reverse the characters of the string\n",
      "\n",
      "9\n",
      "long long int minPlayer(long long int n, long long int k) { long long int num = ((power(k, n) - 1) + mod) % mod; long long int den = (power(k - 1, mod - 2) + mod) % mod; long long int ans = (((num * den) % mod) * k) % mod; return ans; }\n",
      "\n",
      "function to find the minimum required player\n",
      "\n",
      "Function to return the minimum number of players required to make the number of players required to make the number N players\n",
      "\n",
      "10\n",
      "int findLargestSubtreeSumUtil(Node* root, int& ans) { if (root == NULL) return 0; int currSum = root->key + findLargestSubtreeSumUtil(root->left, ans) + findLargestSubtreeSumUtil(root->right, ans); ans = max(ans, currSum); return currSum; }\n",
      "\n",
      "Helper function to find largest subtree sum recursively.\n",
      "\n",
      "Function to find the largest sum of all the subtree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re_bleu4_score = bleu4_score(re_labels_pred, re_labels_act)\n",
    "print(\"The BLEU-4 score using the retrained model: {:.4f}.\".format(re_bleu4_score))\n",
    "print(\"\")\n",
    "print(\"Examples after retraining model\")\n",
    "for i, (code, label, prediction) in enumerate(zip(re_codes_act[10:20], re_labels_act[10:20], re_labels_pred[10:20])):\n",
    "    print(i+1)\n",
    "    print(code)\n",
    "    print(\"\")\n",
    "    print(label)\n",
    "    print(\"\")\n",
    "    print(prediction)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy37",
   "language": "python",
   "name": "newpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
